input {
  jdbc {
    jdbc_driver_library => "/usr/share/logstash/postgresql.jar"
    jdbc_driver_class   => "org.postgresql.Driver"
    jdbc_connection_string => "${JDBC_CONNECTION_STRING}"
    jdbc_user            => "${JDBC_USER}"
    jdbc_password        => "${JDBC_PASSWORD}"
    schedule             => "* * * * *"   # every minute

    statement => "
      SELECT
        al.id,
        al.server_ipaddress      AS server_ipaddress,
        al.port,
        al.request_ipaddress     AS request_ipaddress,
        al.service_name,
        al.server_user,
        al.token_id,
        al.time_to_archive_in_days,
        al.log_level,
        al.archive_strategy,
        al.performer_id,
        al.created_at            AS timestamp,

        -- performer fields
        u.first_name      AS performer_first_name,
        u.last_name       AS performer_last_name,
        u.work_email      AS performer_work_email,
        u.phone_number    AS performer_phone_number,

        -- metadata (single row because OneToOne)
        m.content         AS metadata_content,
        m.metadata_type   AS metadata_type,

        -- action (single row because OneToOne)
        a.name            AS action_name,
        a.description     AS action_description

      FROM audit_log al
      LEFT JOIN metadata m        ON al.metadata_id = m.id AND m.deleted_at IS NULL
      LEFT JOIN action a          ON al.action_id   = a.id AND a.deleted_at IS NULL
      LEFT JOIN user_flat_table u ON al.performer_id = u.id AND u.deleted_at IS NULL
      WHERE al.deleted_at IS NULL
      ORDER BY al.created_at ASC
    "

    # ---- incremental tracking ----
    use_column_value       => true
    tracking_column        => "timestamp"
    tracking_column_type   => "timestamp"
    record_last_run        => true
    last_run_metadata_path => "/usr/share/logstash/data/.logstash_jdbc_last_run"
    clean_run              => false
  }
}

filter {
  mutate { copy => { "timestamp" => "@timestamp" } }

  mutate {
    rename => {
      "id"                     => "logId"
      "server_ipaddress"       => "serverIpAddress"
      "port"                   => "port"
      "request_ipaddress"      => "requestIpAddress"
      "service_name"           => "serviceName"
      "server_user"            => "serverUser"
      "token_id"               => "tokenId"
      "time_to_archive_in_days"=> "timeToArchiveInDays"
      "log_level"              => "logLevel"
      "archive_strategy"       => "archiveStrategy"
      "performer_id"           => "performerId"

      "performer_first_name"   => "[performer][firstName]"
      "performer_last_name"    => "[performer][lastName]"
      "performer_work_email"   => "[performer][workEmail]"
      "performer_phone_number" => "[performer][phoneNumber]"

      "metadata_content"       => "[metadata][content]"
      "metadata_type"          => "[metadata][type]"

      "action_name"            => "[action][name]"
      "action_description"     => "[action][description]"
    }
  }

  date {
    match => ["@timestamp", "ISO8601"]
    timezone => "UTC"
  }
}

output {
  elasticsearch {
    hosts       => ["${ELASTICSEARCH_HOSTS}"]
    index       => "audit_logs-%{+YYYY.MM.dd}"
    document_id => "%{logId}"
  }

  # ---- debugging ----
  stdout { codec => rubydebug }
  file {
    path  => "/usr/share/logstash/logs/debug.log"
    codec => json_lines
  }
}